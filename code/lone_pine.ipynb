{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import statistics as stat\n",
    "from scipy import stats\n",
    "lone_pine = pd.read_csv(r'C:\\Users\\wells\\OneDrive\\Desktop\\lone_pine.csv')\n",
    "crsp_data = pd.read_csv('StockPriceMonthly.csv', encoding='utf8', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine.drop(['% Port', '% OS', 'Hist', 'Change', 'Change.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine['Ticker'] = lone_pine['Ticker'].astype('str')\n",
    "lone_pine['Class'] = lone_pine['Class'].astype('str')\n",
    "def ab(aa):\n",
    "    if '.' in aa:\n",
    "        return aa.split('.')[0]\n",
    "    if '/' in aa:\n",
    "        return aa.split('/')[0]\n",
    "    else:\n",
    "        return aa\n",
    "lone_pine['Ticker'] = lone_pine['Ticker'].apply(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abc(aa):\n",
    "    aa = aa.split('/')\n",
    "    year = aa[2]\n",
    "    month = aa[0]\n",
    "    day = aa[1]\n",
    "    return year+month\n",
    "lone_pine['Date'] = lone_pine['Date'].apply(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine = lone_pine[lone_pine['Class']!='PUT'].loc[lone_pine['Class']!='CALL']\n",
    "lone_pine = lone_pine[lone_pine['Class']!='put'].loc[lone_pine['Class']!='call']\n",
    "lone_pine = lone_pine[lone_pine['Class']!='Put'].loc[lone_pine['Class']!='Call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_3str(df_col):\n",
    "    df_col = df_col.replace(' ', '')\n",
    "    df_col = df_col[0:3]\n",
    "    df_col = df_col.upper()\n",
    "    return df_col\n",
    "lone_pine['Class'] = lone_pine['Class'].apply(class_3str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine_not = lone_pine[lone_pine['Ticker']!='nan']\n",
    "lone_pine_is = lone_pine[lone_pine['Ticker']=='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "lone_pine_not.drop('Name', axis=1, inplace=True)\n",
    "lone_pine_not = lone_pine_not.groupby(['Ticker','Class','Date'])[['Shares', 'Value']].agg('sum').reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "lone_pine_is.loc[:, 'Ticker'] = lone_pine_is['Name']\n",
    "lone_pine_is.drop('Name', axis=1, inplace=True)\n",
    "lone_pine_is = lone_pine_is.groupby(['Ticker','Class','Date'])[['Shares', 'Value']].agg('sum').reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = sorted(list(set(lone_pine_not['Date'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lone_pine = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for num in range(len(date)-1):\n",
    "    first_date = date[num]\n",
    "    second_date = date[num+1]\n",
    "    first_df = lone_pine_not[lone_pine_not['Date']==first_date]\n",
    "    second_df = lone_pine_not[lone_pine_not['Date']==second_date]\n",
    "    first_df = first_df.drop(['Date'],axis=1)\n",
    "    first_df.columns = ['Ticker', 'Class', 'Last_Shares', 'Last_Value']\n",
    "    merge_df = second_df.merge(first_df, on=['Ticker','Class'], how='left')\n",
    "    if len(merge_df) != len(second_df):\n",
    "        print(second_date)\n",
    "    new_lone_pine = pd.concat([new_lone_pine, merge_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lone_pine_is = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(date)-1):\n",
    "    first_date = date[num]\n",
    "    second_date = date[num+1]\n",
    "    first_df = lone_pine_is[lone_pine_is['Date']==first_date]\n",
    "    second_df = lone_pine_is[lone_pine_is['Date']==second_date]\n",
    "    first_df = first_df.drop(['Date'],axis=1)\n",
    "    first_df.columns = ['Ticker', 'Class', 'Last_Shares', 'Last_Value']\n",
    "    merge_df = second_df.merge(first_df, on=['Ticker','Class'], how='left')\n",
    "    if len(merge_df) != len(second_df):\n",
    "        print(second_date)\n",
    "    new_lone_pine_is = pd.concat([new_lone_pine_is, merge_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_lone_pine = pd.concat([new_lone_pine, lone_pine_not[lone_pine_not['Date']==date[0]]], ignore_index=True, sort=False)\n",
    "new_lone_pine_is = pd.concat([new_lone_pine_is, lone_pine_is[lone_pine_is['Date']==date[0]]],ignore_index=True, sort=False)\n",
    "lone_pine_a = pd.concat([new_lone_pine, new_lone_pine_is], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_a = lone_pine_a.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_a.loc[:, 'Shares_Change'] = lone_pine_a['Shares'] - lone_pine_a['Last_Shares']\n",
    "lone_pine_a.loc[:, 'Value_Change'] = lone_pine_a['Value'] - lone_pine_a['Last_Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_a.drop(['Last_Shares', 'Last_Value'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d1d06979a845d08c02b9582aa90f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3181), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "add_df = pd.DataFrame(columns=lone_pine_a.columns)\n",
    "for index in tqdm_notebook(range(len(lone_pine_a))):\n",
    "    each_data = lone_pine_a.loc[index]\n",
    "    each_data = list(each_data)\n",
    "    date = int(each_data[2])\n",
    "    if date % 4 == 0:\n",
    "        date = date - 12 + 100\n",
    "    each_data[2] = str(date+1)\n",
    "    each_data[5] = 0\n",
    "    each_data[6] = 0\n",
    "    add_df.loc[-1] = each_data\n",
    "    add_df = add_df.reset_index(drop=True)\n",
    "    date = int(each_data[2])\n",
    "    each_data[2] = str(date+1)\n",
    "    each_data[5] = 0\n",
    "    each_data[6] = 0\n",
    "    add_df.loc[-1] = each_data\n",
    "    add_df = add_df.reset_index(drop=True)\n",
    "lone_pine_a = pd.concat([lone_pine_a, add_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_a.drop(lone_pine_a[lone_pine_a['Shares']==0].loc[lone_pine_a['Value']==0].loc[lone_pine_a['Shares_Change']==0].loc[lone_pine_a['Value_Change']==0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_(df_col):\n",
    "    if df_col == 'CLA':\n",
    "        return 'A'\n",
    "    elif df_col == 'CLB':\n",
    "        return 'B'\n",
    "    elif df_col == 'CLC':\n",
    "        return 'C'\n",
    "    elif df_col == 'CLD':\n",
    "        return 'D'\n",
    "    else:\n",
    "        return df_col\n",
    "lone_pine_a['Class'] = lone_pine_a['Class'].apply(class_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def division(df):\n",
    "    if df['Shares_Change'] == 0 and df['Shares'] == 0:\n",
    "        return 0\n",
    "    elif df['Shares'] == 0 and df['Value'] == 0:\n",
    "        return df['Value_Change'] / df['Shares_Change']\n",
    "    else:\n",
    "        return df['Value'] / df['Shares']\n",
    "lone_pine_a['price'] = lone_pine_a.apply(division, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abcd(aa):\n",
    "    return str(aa)[0:6]\n",
    "crsp_data['date'] = crsp_data['date'].apply(abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crsp_data.columns = ['PERMNO', 'Date', 'Ticker', 'COMNAM', 'Class', 'DIVAMT', 'PRC', 'VOL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_abs(df_col):\n",
    "    return abs(df_col)\n",
    "crsp_data_c = crsp_data[['Date', 'Ticker', 'PRC', 'Class']]\n",
    "crsp_data_c = crsp_data_c[crsp_data_c['Ticker'].isin(list(set(lone_pine_a['Ticker'])))]\n",
    "crsp_data_c = crsp_data_c[crsp_data_c['PRC'].notnull()].drop_duplicates(keep='first')\n",
    "crsp_data_c['PRC'] = crsp_data_c['PRC'].apply(to_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crsp_data_c = crsp_data_c.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)\n",
    "# df_list = []\n",
    "# for each in tqdm_notebook(crsp_data_c.groupby(by='Ticker')):\n",
    "#     ticker, df = each\n",
    "#     df.loc[:, 'Last_PRC'] = df['PRC'].shift()\n",
    "#     df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8494412899017334\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import time\n",
    "from function import test_function\n",
    "if __name__ == '__main__':\n",
    "    a = time.time()\n",
    "    pool_list = [i for i in crsp_data_c.groupby(by='Ticker')]\n",
    "    pool = mp.Pool(processes=5)\n",
    "    df_list = pool.map(test_function.last_price, pool_list)\n",
    "    b = time.time()\n",
    "    print(b - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_data_c = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine_all = lone_pine_a.merge(crsp_data_c, on=['Date', 'Ticker'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker in list(set(list(lone_pine_all['Ticker']))):\n",
    "    if len(lone_pine_a[lone_pine_a['Ticker']==ticker].reset_index(drop=True)) != len(lone_pine_all[lone_pine_all['Ticker']==ticker].reset_index(drop=True)):\n",
    "        drop_df = lone_pine_all[lone_pine_all['Ticker']==ticker].loc[lone_pine_all['Class_x']!=lone_pine_all['Class_y']]\n",
    "        lone_pine_all.drop(list(drop_df.index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lone_pine_all = lone_pine_all.sort_values(by='Date').reset_index(drop=True)\n",
    "# df_list = []\n",
    "# for each in tqdm_notebook(lone_pine_all.groupby(by='Ticker')):\n",
    "#     ticker, df = each\n",
    "#     df.loc[:, 'Last_price'] = df['price'].shift()\n",
    "#     df.loc[:, 'Last_PRC'] = df['PRC'].shift()\n",
    "#     df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lone_pine_all = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = lone_pine_all[lone_pine_all['PRC'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b7045dc40a479ab6e7ee54a5bb66c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=364), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test = lone_pine_all\n",
    "new_error = []\n",
    "for index in tqdm_notebook(error.index):\n",
    "    each = error.loc[index]\n",
    "    df = crsp_data[crsp_data['Ticker']==each['Ticker']]\n",
    "    try:\n",
    "        if int(each['Date']) > int(list(df['Date'])[-1]):\n",
    "            test = test.drop(index)\n",
    "        else:\n",
    "            new_error.append(list(each))\n",
    "    except:\n",
    "        new_error.append(list(each))\n",
    "lone_pine_all = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_error = pd.DataFrame(new_error)\n",
    "new_error.columns = lone_pine_all.columns\n",
    "new_error = new_error.sort_values(by='Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123ae79b412c40f19ccb4672adbbb2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for each in tqdm_notebook(new_error.groupby(by='Ticker')):\n",
    "    ticker, df = each\n",
    "    df.loc[:, 'PRC'] = df['price']\n",
    "    df.loc[:, 'Last_PRC'] = df['PRC'].shift()\n",
    "    df_list.append(df)\n",
    "new_error = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all = pd.concat([lone_pine_all[lone_pine_all['PRC'].notnull()], new_error], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(new_error).to_csv('error.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lone_pine_all = lone_pine_all.sort_values(by=['Ticker', 'Date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = lone_pine_all\n",
    "for each in lone_pine_all.groupby('Ticker'):\n",
    "    ticker, df = each\n",
    "    for index in df.index[:-1]:\n",
    "        if df.loc[index]['Shares']==0 and df.loc[index+1]['Shares']==0:\n",
    "            test.drop(index+1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all.drop(['Class_x', 'price'], axis=1, inplace=True)\n",
    "lone_pine_all.columns = ['Ticker', 'Date', 'Shares', 'Value', 'Shares_Change', 'Value_Change', 'Price',\n",
    "                         'Class', 'Last_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "new_share = lone_pine_all.loc[lone_pine_all['Shares']==lone_pine_all['Shares_Change']]\n",
    "new_share.loc[:,'New_Value'] = new_share['Shares'] * new_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_share.to_csv('new_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_share = lone_pine_all[lone_pine_all['Shares']==0]\n",
    "sell_share.loc[:,'New_Value'] = sell_share['Shares_Change'] * sell_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_share.to_csv('sell_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_share = lone_pine_all[lone_pine_all['Shares_Change']>0].loc[lone_pine_all['Shares']!=lone_pine_all['Shares_Change']]\n",
    "more_share.loc[:,'New_Value'] = more_share['Shares'] * more_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_share.to_csv('more_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_share = lone_pine_all[lone_pine_all['Shares_Change']<0].loc[lone_pine_all['Shares']!=0]\n",
    "less_share.loc[:,'New_Value'] = (less_share['Shares'] + abs(less_share['Shares_Change'])) * less_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "less_share.to_csv('less_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_share = lone_pine_all[lone_pine_all['Shares_Change']==0]\n",
    "same_share.loc[:,'New_Value'] = same_share['Shares'] * same_share['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_share.to_csv('same_share.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lone_pine_all.loc[:,'New_Value'] = lone_pine_all['Shares'] * lone_pine_all['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_asset = []\n",
    "for date in list(set(lone_pine_all['Date'])):\n",
    "    lone_pine_all_t = lone_pine_all[lone_pine_all['Date']==date]\n",
    "    total_asset.append(sum(lone_pine_all_t['New_Value']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue = []\n",
    "for date in list(set(lone_pine_all['Date'])):\n",
    "    lone_pine_all_t = lone_pine_all[lone_pine_all['Date']==date]\n",
    "\n",
    "    sell_shares = lone_pine_all_t[lone_pine_all_t['Shares']==0]\n",
    "    more_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']>0].loc[lone_pine_all_t['Shares']!=lone_pine_all_t['Shares_Change']]\n",
    "    less_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']<0].loc[lone_pine_all_t['Shares']!=0]\n",
    "    same_shares = lone_pine_all_t[lone_pine_all_t['Shares_Change']==0]\n",
    "\n",
    "    sell_shares.loc[:,'diff'] = abs(sell_shares['Shares_Change']) * ((sell_shares['Price'] - sell_shares['Last_Price']) / 2)\n",
    "    more_shares.loc[:,'diff'] = (more_shares['Shares'] - more_shares['Shares_Change']) * (more_shares['Price'] - more_shares['Last_Price'])\n",
    "    less_shares.loc[:,'diff'] = less_shares['Shares'] * (less_shares['Price'] - less_shares['Last_Price']) + abs(less_shares['Shares_Change']) * ((less_shares['Price'] - less_shares['Last_Price']) / 2)\n",
    "    same_shares.loc[:,'diff'] = same_shares['Shares'] * (same_shares['Price'] - same_shares['Last_Price'])\n",
    "    \n",
    "    sell_shares = sell_shares[sell_shares['diff'].notnull()]\n",
    "    more_shares = more_shares[more_shares['diff'].notnull()]\n",
    "    less_shares = less_shares[less_shares['diff'].notnull()]\n",
    "    same_shares = same_shares[same_shares['diff'].notnull()]\n",
    "    \n",
    "    revenue.append(sum(sell_shares['diff']) + sum(more_shares['diff']) + sum(less_shares['diff']) + sum(same_shares['diff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = pd.DataFrame({'date':list(set(lone_pine_all['Date'])),\n",
    "                          'asset':total_asset,\n",
    "                          'revenue':revenue})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = revenue_df.sort_values(by='date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df['last_asset'] = revenue_df['asset'].shift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df['return_rate'] = round(revenue_df['revenue'] / revenue_df['last_asset'] * 100, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = revenue_df[0:-2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_df.to_csv('revenue.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "revenue_df = revenue_df[1:]\n",
    "revenue_df = revenue_df[revenue_df['return_rate']<40].loc[revenue_df['return_rate']>(-40)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fama = pd.read_csv('fama.csv')\n",
    "fama['date'] = fama['date'].astype('str')\n",
    "\n",
    "fama_3 = fama.merge(revenue_df[['date', 'return_rate']], on='date', how='left')\n",
    "\n",
    "fama_3 = fama_3[fama_3['return_rate'].notnull()]\n",
    "\n",
    "fama_3['return_rate'] = fama_3['return_rate'] - fama_3['RF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fama = pd.read_csv('fama5.csv')\n",
    "fama['date'] = fama['date'].astype('str')\n",
    "\n",
    "fama_5 = fama.merge(revenue_df[['date', 'return_rate']], on='date', how='left')\n",
    "\n",
    "fama_5 = fama_5[fama_5['return_rate'].notnull()]\n",
    "\n",
    "fama_5['return_rate'] = fama_5['return_rate'] - fama_5['RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "# alpha = 10\n",
    "# while alpha > 0.01:\n",
    "for i in range(10):\n",
    "    x = fama_3[['Mkt-RF', 'SMB', 'HML']].values\n",
    "    y = fama_3[['return_rate']].values\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "    x_train_std = sc.transform(x_train)\n",
    "    x_test_std = sc.transform(x_test)\n",
    "    lassocv = LassoCV()\n",
    "    lassocv.fit(x_train_std, y_train)\n",
    "    alpha = lassocv.alpha_\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(x_train_std, y_train)\n",
    "    y_predict_train = lasso.predict(x_train_std)\n",
    "    score_train = r2_score(y_train, y_predict_train)\n",
    "    y_predict = lasso.predict(x_test_std)\n",
    "    score = r2_score(y_test, y_predict)\n",
    "    coeff_used = np.sum(lasso.coef_!=0)\n",
    "    e = mean_squared_error(y_test, y_predict)\n",
    "    alpha_df.loc[-1] = [alpha] + list(lasso.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "#     alpha = alpha - 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "      <th>coeff_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003553</td>\n",
       "      <td>3.881883</td>\n",
       "      <td>0.155247</td>\n",
       "      <td>-1.319709</td>\n",
       "      <td>0.579118</td>\n",
       "      <td>0.873415</td>\n",
       "      <td>3.854697</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034140</td>\n",
       "      <td>4.241306</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.385199</td>\n",
       "      <td>0.624422</td>\n",
       "      <td>0.836024</td>\n",
       "      <td>3.481612</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104560</td>\n",
       "      <td>4.041007</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.001369</td>\n",
       "      <td>0.620623</td>\n",
       "      <td>0.819369</td>\n",
       "      <td>4.311621</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041759</td>\n",
       "      <td>4.236401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.489033</td>\n",
       "      <td>0.626207</td>\n",
       "      <td>0.811061</td>\n",
       "      <td>3.679202</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.088802</td>\n",
       "      <td>4.089489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.435677</td>\n",
       "      <td>0.632959</td>\n",
       "      <td>0.783468</td>\n",
       "      <td>5.166364</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004082</td>\n",
       "      <td>4.273964</td>\n",
       "      <td>0.264646</td>\n",
       "      <td>-1.266133</td>\n",
       "      <td>0.643415</td>\n",
       "      <td>0.761484</td>\n",
       "      <td>4.608148</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.076253</td>\n",
       "      <td>4.344211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.252608</td>\n",
       "      <td>0.651617</td>\n",
       "      <td>0.723442</td>\n",
       "      <td>5.612384</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.108908</td>\n",
       "      <td>4.299477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.342961</td>\n",
       "      <td>0.658074</td>\n",
       "      <td>0.696805</td>\n",
       "      <td>5.582236</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.070800</td>\n",
       "      <td>4.491572</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>-1.202729</td>\n",
       "      <td>0.670821</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>4.709472</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053030</td>\n",
       "      <td>4.519074</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>-1.248883</td>\n",
       "      <td>0.674056</td>\n",
       "      <td>0.620129</td>\n",
       "      <td>5.531237</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      alpha     coef1     coef2     coef3  train_score  test_score         e  \\\n",
       "4  0.003553  3.881883  0.155247 -1.319709     0.579118    0.873415  3.854697   \n",
       "7  0.034140  4.241306  0.000000 -1.385199     0.624422    0.836024  3.481612   \n",
       "1  0.104560  4.041007 -0.000000 -1.001369     0.620623    0.819369  4.311621   \n",
       "2  0.041759  4.236401  0.000000 -1.489033     0.626207    0.811061  3.679202   \n",
       "8  0.088802  4.089489  0.000000 -1.435677     0.632959    0.783468  5.166364   \n",
       "5  0.004082  4.273964  0.264646 -1.266133     0.643415    0.761484  4.608148   \n",
       "9  0.076253  4.344211  0.000000 -1.252608     0.651617    0.723442  5.612384   \n",
       "0  0.108908  4.299477  0.000000 -1.342961     0.658074    0.696805  5.582236   \n",
       "6  0.070800  4.491572  0.007387 -1.202729     0.670821    0.628125  4.709472   \n",
       "3  0.053030  4.519074  0.016663 -1.248883     0.674056    0.620129  5.531237   \n",
       "\n",
       "   coeff_used  \n",
       "4         3.0  \n",
       "7         2.0  \n",
       "1         2.0  \n",
       "2         2.0  \n",
       "8         2.0  \n",
       "5         3.0  \n",
       "9         2.0  \n",
       "0         2.0  \n",
       "6         3.0  \n",
       "3         3.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_df.sort_values(by='test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n",
      "C:\\Users\\wells\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:304: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  F = corr ** 2 / (1 - corr ** 2) * degrees_of_freedom\n"
     ]
    }
   ],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'coef1_p', 'coef2_p', 'coef3_p', 'coef4_p', 'coef5_p', 'train_score', 'test_score', 'e'])\n",
    "alpha = 3\n",
    "while alpha > 0.1:\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = lasso.predict(x_train_std)\n",
    "    score_train=r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = lasso.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    p_value = list(f_regression(x_test.values, y_predict)[1])\n",
    "    alpha_df.loc[-1] = [alpha] + list(lasso.coef_) + p_value + [score_train, score, e]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.610228573517401\n",
      "test_score: 0.8464889587156124\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>coef4</th>\n",
       "      <th>coef5</th>\n",
       "      <th>coef1_p</th>\n",
       "      <th>coef2_p</th>\n",
       "      <th>coef3_p</th>\n",
       "      <th>coef4_p</th>\n",
       "      <th>coef5_p</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.2</td>\n",
       "      <td>3.476344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.824973</td>\n",
       "      <td>-0.619526</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.610229</td>\n",
       "      <td>0.846489</td>\n",
       "      <td>4.315371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.3</td>\n",
       "      <td>3.357322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.786695</td>\n",
       "      <td>-0.512318</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.604931</td>\n",
       "      <td>0.843261</td>\n",
       "      <td>4.406103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.4</td>\n",
       "      <td>3.238300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.748417</td>\n",
       "      <td>-0.405110</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.597514</td>\n",
       "      <td>0.837466</td>\n",
       "      <td>4.569024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.5</td>\n",
       "      <td>3.119226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.710211</td>\n",
       "      <td>-0.297857</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.587978</td>\n",
       "      <td>0.829099</td>\n",
       "      <td>4.804230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3.000227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.671902</td>\n",
       "      <td>-0.190668</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.818168</td>\n",
       "      <td>5.111495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.7</td>\n",
       "      <td>2.881205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.633625</td>\n",
       "      <td>-0.083460</td>\n",
       "      <td>8.748954e-17</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.073089</td>\n",
       "      <td>0.777133</td>\n",
       "      <td>0.562550</td>\n",
       "      <td>0.804669</td>\n",
       "      <td>5.490990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha     coef1  coef2  coef3     coef4     coef5       coef1_p   coef2_p  \\\n",
       "28    0.2  3.476344    0.0    0.0 -0.824973 -0.619526  8.748954e-17  0.000318   \n",
       "27    0.3  3.357322    0.0    0.0 -0.786695 -0.512318  8.748954e-17  0.000318   \n",
       "26    0.4  3.238300    0.0    0.0 -0.748417 -0.405110  8.748954e-17  0.000318   \n",
       "25    0.5  3.119226    0.0    0.0 -0.710211 -0.297857  8.748954e-17  0.000318   \n",
       "24    0.6  3.000227    0.0    0.0 -0.671902 -0.190668  8.748954e-17  0.000318   \n",
       "23    0.7  2.881205    0.0   -0.0 -0.633625 -0.083460  8.748954e-17  0.000318   \n",
       "\n",
       "    coef3_p   coef4_p   coef5_p  train_score  test_score         e  \n",
       "28  0.00504  0.073089  0.777133     0.610229    0.846489  4.315371  \n",
       "27  0.00504  0.073089  0.777133     0.604931    0.843261  4.406103  \n",
       "26  0.00504  0.073089  0.777133     0.597514    0.837466  4.569024  \n",
       "25  0.00504  0.073089  0.777133     0.587978    0.829099  4.804230  \n",
       "24  0.00504  0.073089  0.777133     0.576324    0.818168  5.111495  \n",
       "23  0.00504  0.073089  0.777133     0.562550    0.804669  5.490990  "
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))\n",
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "alpha = 5\n",
    "while alpha >= 0.001:\n",
    "    rr = Ridge(alpha)\n",
    "    rr.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = rr.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = rr.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(rr.coef_!=0)\n",
    "    alpha_df.loc[-1] = [alpha] + list(rr.coef_) + [score_train, score, e, coeff_used]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.66728240095804\n",
      "test_score: 0.6462843705034473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "      <th>coeff_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.000</td>\n",
       "      <td>4.441198</td>\n",
       "      <td>0.104099</td>\n",
       "      <td>-1.402750</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.646284</td>\n",
       "      <td>3.354514</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.999</td>\n",
       "      <td>4.441240</td>\n",
       "      <td>0.104085</td>\n",
       "      <td>-1.402767</td>\n",
       "      <td>0.665962</td>\n",
       "      <td>0.646280</td>\n",
       "      <td>3.354555</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.998</td>\n",
       "      <td>4.441281</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>-1.402785</td>\n",
       "      <td>0.665963</td>\n",
       "      <td>0.646276</td>\n",
       "      <td>3.354595</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.997</td>\n",
       "      <td>4.441323</td>\n",
       "      <td>0.104058</td>\n",
       "      <td>-1.402802</td>\n",
       "      <td>0.665963</td>\n",
       "      <td>0.646272</td>\n",
       "      <td>3.354636</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.996</td>\n",
       "      <td>4.441365</td>\n",
       "      <td>0.104044</td>\n",
       "      <td>-1.402819</td>\n",
       "      <td>0.665964</td>\n",
       "      <td>0.646267</td>\n",
       "      <td>3.354676</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.995</td>\n",
       "      <td>4.441406</td>\n",
       "      <td>0.104030</td>\n",
       "      <td>-1.402837</td>\n",
       "      <td>0.665964</td>\n",
       "      <td>0.646263</td>\n",
       "      <td>3.354717</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha     coef1     coef2     coef3  train_score  test_score         e  \\\n",
       "0  5.000  4.441198  0.104099 -1.402750     0.665962    0.646284  3.354514   \n",
       "1  4.999  4.441240  0.104085 -1.402767     0.665962    0.646280  3.354555   \n",
       "2  4.998  4.441281  0.104072 -1.402785     0.665963    0.646276  3.354595   \n",
       "3  4.997  4.441323  0.104058 -1.402802     0.665963    0.646272  3.354636   \n",
       "4  4.996  4.441365  0.104044 -1.402819     0.665964    0.646267  3.354676   \n",
       "5  4.995  4.441406  0.104030 -1.402837     0.665964    0.646263  3.354717   \n",
       "\n",
       "   coeff_used  \n",
       "0         3.0  \n",
       "1         3.0  \n",
       "2         3.0  \n",
       "3         3.0  \n",
       "4         3.0  \n",
       "5         3.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))\n",
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'coef1_p', 'coef2_p', 'coef3_p', 'coef4_p', 'coef5_p', 'train_score', 'test_score', 'e'])\n",
    "alpha = 5\n",
    "while alpha >= 0.001:\n",
    "    rr = Ridge(alpha)\n",
    "    rr.fit(x_train_std, y_train['return_rate'].values)\n",
    "    y_predict_train = rr.predict(x_train_std)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = rr.predict(x_test_std)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    p_value = list(f_regression(x_test.values, y_predict)[1])\n",
    "    alpha_df.loc[-1] = [alpha] + list(rr.coef_) + p_value + [score_train, score, e]\n",
    "    alpha_df = alpha_df.reset_index(drop=True)\n",
    "    alpha = alpha - 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.6585122571984281\n",
      "test_score: 0.7544180451815767\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>coef4</th>\n",
       "      <th>coef5</th>\n",
       "      <th>coef1_p</th>\n",
       "      <th>coef2_p</th>\n",
       "      <th>coef3_p</th>\n",
       "      <th>coef4_p</th>\n",
       "      <th>coef5_p</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.000</td>\n",
       "      <td>3.884055</td>\n",
       "      <td>0.303819</td>\n",
       "      <td>0.154633</td>\n",
       "      <td>-0.804263</td>\n",
       "      <td>-0.956155</td>\n",
       "      <td>1.981900e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.657301</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>6.388850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.999</td>\n",
       "      <td>3.884093</td>\n",
       "      <td>0.303813</td>\n",
       "      <td>0.154644</td>\n",
       "      <td>-0.804262</td>\n",
       "      <td>-0.956169</td>\n",
       "      <td>1.982238e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799902</td>\n",
       "      <td>0.657302</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>6.388857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.998</td>\n",
       "      <td>3.884131</td>\n",
       "      <td>0.303807</td>\n",
       "      <td>0.154655</td>\n",
       "      <td>-0.804261</td>\n",
       "      <td>-0.956183</td>\n",
       "      <td>1.982576e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799911</td>\n",
       "      <td>0.657302</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>6.388864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.997</td>\n",
       "      <td>3.884168</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.154666</td>\n",
       "      <td>-0.804260</td>\n",
       "      <td>-0.956197</td>\n",
       "      <td>1.982913e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799920</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.754417</td>\n",
       "      <td>6.388870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.996</td>\n",
       "      <td>3.884206</td>\n",
       "      <td>0.303795</td>\n",
       "      <td>0.154676</td>\n",
       "      <td>-0.804259</td>\n",
       "      <td>-0.956211</td>\n",
       "      <td>1.983251e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799929</td>\n",
       "      <td>0.657303</td>\n",
       "      <td>0.754417</td>\n",
       "      <td>6.388877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.995</td>\n",
       "      <td>3.884243</td>\n",
       "      <td>0.303789</td>\n",
       "      <td>0.154687</td>\n",
       "      <td>-0.804258</td>\n",
       "      <td>-0.956225</td>\n",
       "      <td>1.983589e-26</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.799938</td>\n",
       "      <td>0.657304</td>\n",
       "      <td>0.754417</td>\n",
       "      <td>6.388884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha     coef1     coef2     coef3     coef4     coef5       coef1_p  \\\n",
       "0  5.000  3.884055  0.303819  0.154633 -0.804263 -0.956155  1.981900e-26   \n",
       "1  4.999  3.884093  0.303813  0.154644 -0.804262 -0.956169  1.982238e-26   \n",
       "2  4.998  3.884131  0.303807  0.154655 -0.804261 -0.956183  1.982576e-26   \n",
       "3  4.997  3.884168  0.303801  0.154666 -0.804260 -0.956197  1.982913e-26   \n",
       "4  4.996  3.884206  0.303795  0.154676 -0.804259 -0.956211  1.983251e-26   \n",
       "5  4.995  3.884243  0.303789  0.154687 -0.804258 -0.956225  1.983589e-26   \n",
       "\n",
       "    coef2_p  coef3_p   coef4_p   coef5_p  train_score  test_score         e  \n",
       "0  0.001636  0.00014  0.000002  0.799893     0.657301    0.754418  6.388850  \n",
       "1  0.001636  0.00014  0.000002  0.799902     0.657302    0.754418  6.388857  \n",
       "2  0.001636  0.00014  0.000002  0.799911     0.657302    0.754418  6.388864  \n",
       "3  0.001636  0.00014  0.000002  0.799920     0.657303    0.754417  6.388870  \n",
       "4  0.001636  0.00014  0.000002  0.799929     0.657303    0.754417  6.388877  \n",
       "5  0.001636  0.00014  0.000002  0.799938     0.657304    0.754417  6.388884  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_score:',max(alpha_df['train_score']))\n",
    "print('test_score:',max(alpha_df['test_score']))\n",
    "alpha_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "# x_train_std = sc.transform(x_train)\n",
    "# x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.DataFrame(columns=['c', 'coef1', 'coef2', 'coef3', 'train_score', 'test_score', 'e', 'coeff_used'])\n",
    "c = 100\n",
    "while c > 1:\n",
    "    svr_lin = SVR(kernel='linear', C=c, gamma='auto')\n",
    "    svr_lin.fit(x_train.values, y_train['return_rate'].values)\n",
    "    y_predict_train = svr_lin.predict(x_train.values)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = svr_lin.predict(x_test.values)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    coeff_used = np.sum(svr_lin.coef_!=0)\n",
    "    c_df.loc[-1] = [c] + list(svr_lin.coef_[0]) + [score_train, score, e, coeff_used]\n",
    "    c_df = c_df.reset_index(drop=True)\n",
    "    c = c - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.6586496596708757\n",
      "test_score: 0.7729431644215765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "      <th>coeff_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.007111</td>\n",
       "      <td>-0.018663</td>\n",
       "      <td>-0.524920</td>\n",
       "      <td>0.636665</td>\n",
       "      <td>0.770790</td>\n",
       "      <td>5.163847</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.007122</td>\n",
       "      <td>-0.018882</td>\n",
       "      <td>-0.524921</td>\n",
       "      <td>0.636664</td>\n",
       "      <td>0.770758</td>\n",
       "      <td>5.164566</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>89.0</td>\n",
       "      <td>1.007159</td>\n",
       "      <td>-0.018628</td>\n",
       "      <td>-0.525132</td>\n",
       "      <td>0.636665</td>\n",
       "      <td>0.770746</td>\n",
       "      <td>5.164828</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.007063</td>\n",
       "      <td>-0.018701</td>\n",
       "      <td>-0.525030</td>\n",
       "      <td>0.636665</td>\n",
       "      <td>0.770744</td>\n",
       "      <td>5.164880</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1.007154</td>\n",
       "      <td>-0.018502</td>\n",
       "      <td>-0.525209</td>\n",
       "      <td>0.636666</td>\n",
       "      <td>0.770743</td>\n",
       "      <td>5.164888</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.007155</td>\n",
       "      <td>-0.018622</td>\n",
       "      <td>-0.525176</td>\n",
       "      <td>0.636666</td>\n",
       "      <td>0.770740</td>\n",
       "      <td>5.164973</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       c     coef1     coef2     coef3  train_score  test_score         e  \\\n",
       "98   2.0  1.007111 -0.018663 -0.524920     0.636665    0.770790  5.163847   \n",
       "96   4.0  1.007122 -0.018882 -0.524921     0.636664    0.770758  5.164566   \n",
       "11  89.0  1.007159 -0.018628 -0.525132     0.636665    0.770746  5.164828   \n",
       "97   3.0  1.007063 -0.018701 -0.525030     0.636665    0.770744  5.164880   \n",
       "5   95.0  1.007154 -0.018502 -0.525209     0.636666    0.770743  5.164888   \n",
       "81  19.0  1.007155 -0.018622 -0.525176     0.636666    0.770740  5.164973   \n",
       "\n",
       "    coeff_used  \n",
       "98         3.0  \n",
       "96         3.0  \n",
       "11         3.0  \n",
       "97         3.0  \n",
       "5          3.0  \n",
       "81         3.0  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('c_df:',max(alpha_df['train_score']))\n",
    "print('c_df:',max(alpha_df['test_score']))\n",
    "c_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "# sc = StandardScaler()\n",
    "# sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "# x_train_std = sc.transform(x_train)\n",
    "# x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_df = pd.DataFrame(columns=['alpha', 'coef1', 'coef2', 'coef3', 'coef4', 'coef5', 'coef1_p', 'coef2_p', 'coef3_p', 'coef4_p', 'coef5_p', 'train_score', 'test_score', 'e'])\n",
    "c = 100\n",
    "while c > 1:\n",
    "    svr_lin = SVR(kernel='linear', C=c, gamma='auto')\n",
    "    svr_lin.fit(x_train.values, y_train['return_rate'].values)\n",
    "    y_predict_train = svr_lin.predict(x_train.values)\n",
    "    score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "    y_predict = svr_lin.predict(x_test.values)\n",
    "    score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "    e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "    p_value = list(f_regression(x_test.values, y_predict)[1])\n",
    "    c_df.loc[-1] = [c] + list(svr_lin.coef_[0])+ p_value + [score_train, score, e]\n",
    "    c_df = c_df.reset_index(drop=True)\n",
    "    c = c - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.8021993783469004\n",
      "test_score: 0.46243317034036435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>coef1</th>\n",
       "      <th>coef2</th>\n",
       "      <th>coef3</th>\n",
       "      <th>coef4</th>\n",
       "      <th>coef5</th>\n",
       "      <th>coef1_p</th>\n",
       "      <th>coef2_p</th>\n",
       "      <th>coef3_p</th>\n",
       "      <th>coef4_p</th>\n",
       "      <th>coef5_p</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0.986618</td>\n",
       "      <td>-0.025050</td>\n",
       "      <td>-0.038976</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.256500</td>\n",
       "      <td>1.371124e-22</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.018438</td>\n",
       "      <td>0.135185</td>\n",
       "      <td>0.802195</td>\n",
       "      <td>0.462433</td>\n",
       "      <td>20.151475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>52.0</td>\n",
       "      <td>0.986618</td>\n",
       "      <td>-0.025056</td>\n",
       "      <td>-0.038987</td>\n",
       "      <td>-0.436187</td>\n",
       "      <td>-0.256508</td>\n",
       "      <td>1.370820e-22</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>0.135184</td>\n",
       "      <td>0.802195</td>\n",
       "      <td>0.462432</td>\n",
       "      <td>20.151521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>59.0</td>\n",
       "      <td>0.986623</td>\n",
       "      <td>-0.025038</td>\n",
       "      <td>-0.038988</td>\n",
       "      <td>-0.436189</td>\n",
       "      <td>-0.256490</td>\n",
       "      <td>1.368084e-22</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.018443</td>\n",
       "      <td>0.135214</td>\n",
       "      <td>0.802195</td>\n",
       "      <td>0.462430</td>\n",
       "      <td>20.151581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.986598</td>\n",
       "      <td>-0.025098</td>\n",
       "      <td>-0.039071</td>\n",
       "      <td>-0.435930</td>\n",
       "      <td>-0.256591</td>\n",
       "      <td>1.365216e-22</td>\n",
       "      <td>0.004977</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.018458</td>\n",
       "      <td>0.135195</td>\n",
       "      <td>0.802195</td>\n",
       "      <td>0.462419</td>\n",
       "      <td>20.151999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>93.0</td>\n",
       "      <td>0.986666</td>\n",
       "      <td>-0.025047</td>\n",
       "      <td>-0.038865</td>\n",
       "      <td>-0.435803</td>\n",
       "      <td>-0.256565</td>\n",
       "      <td>1.352063e-22</td>\n",
       "      <td>0.004973</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>0.462419</td>\n",
       "      <td>20.152015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.0</td>\n",
       "      <td>0.986664</td>\n",
       "      <td>-0.025013</td>\n",
       "      <td>-0.038805</td>\n",
       "      <td>-0.435805</td>\n",
       "      <td>-0.256518</td>\n",
       "      <td>1.347018e-22</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.018491</td>\n",
       "      <td>0.135355</td>\n",
       "      <td>0.802195</td>\n",
       "      <td>0.462418</td>\n",
       "      <td>20.152050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha     coef1     coef2     coef3     coef4     coef5       coef1_p  \\\n",
       "45   55.0  0.986618 -0.025050 -0.038976 -0.436207 -0.256500  1.371124e-22   \n",
       "48   52.0  0.986618 -0.025056 -0.038987 -0.436187 -0.256508  1.370820e-22   \n",
       "41   59.0  0.986623 -0.025038 -0.038988 -0.436189 -0.256490  1.368084e-22   \n",
       "77   23.0  0.986598 -0.025098 -0.039071 -0.435930 -0.256591  1.365216e-22   \n",
       "7    93.0  0.986666 -0.025047 -0.038865 -0.435803 -0.256565  1.352063e-22   \n",
       "3    97.0  0.986664 -0.025013 -0.038805 -0.435805 -0.256518  1.347018e-22   \n",
       "\n",
       "     coef2_p   coef3_p   coef4_p   coef5_p  train_score  test_score          e  \n",
       "45  0.004976  0.000512  0.018438  0.135185     0.802195    0.462433  20.151475  \n",
       "48  0.004976  0.000512  0.018439  0.135184     0.802195    0.462432  20.151521  \n",
       "41  0.004975  0.000512  0.018443  0.135214     0.802195    0.462430  20.151581  \n",
       "77  0.004977  0.000511  0.018458  0.135195     0.802195    0.462419  20.151999  \n",
       "7   0.004973  0.000512  0.018483  0.135301     0.802196    0.462419  20.152015  \n",
       "3   0.004970  0.000512  0.018491  0.135355     0.802195    0.462418  20.152050  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('train_score:',max(c_df['train_score']))\n",
    "print('test_score:',max(c_df['test_score']))\n",
    "c_df.sort_values(by='test_score', ascending=False)[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = fama_3[['Mkt-RF', 'SMB', 'HML']]\n",
    "y = fama_3[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [ 4.46592634  0.06357718 -1.35955519]\n",
      "score_train: 0.6401981679388165\n",
      "score_prediction: 0.8148616306550289\n",
      "e: 3.1491292009718395\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(alpha)\n",
    "lr.fit(x_train_std, y_train['return_rate'].values)\n",
    "y_predict_train = lr.predict(x_train_std)\n",
    "score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "y_predict = lr.predict(x_test_std)\n",
    "score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "coeff_used = np.sum(lr.coef_!=0)\n",
    "print('coef:', lr.coef_)\n",
    "print('score_train:',score_train)\n",
    "print('score_prediction:',score)\n",
    "print('e:',e)\n",
    "# list(lr.coef_) + [score_train, score, e, coeff_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = fama_5[['Mkt-RF', 'SMB', 'RMW', 'CMA', 'HML']]\n",
    "y = fama_5[['return_rate']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train)  #可以使用計算得到的均值和方差來對訓練資料做標準化處理\n",
    "x_train_std = sc.transform(x_train)\n",
    "x_test_std = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef: [ 4.18158537  0.25835828  0.3891332  -0.87641394 -0.70706281]\n",
      "score_train: 0.6742320622269391\n",
      "score_prediction: 0.7177033747243396\n",
      "e: 5.904786682514618\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression(alpha)\n",
    "lr.fit(x_train_std, y_train['return_rate'].values)\n",
    "y_predict_train = lr.predict(x_train_std)\n",
    "score_train = r2_score(y_train['return_rate'].values, y_predict_train)\n",
    "y_predict = lr.predict(x_test_std)\n",
    "score=r2_score(y_test['return_rate'].values, y_predict)\n",
    "e = mean_squared_error(y_test['return_rate'].values, y_predict)\n",
    "coeff_used = np.sum(lr.coef_!=0)\n",
    "print('coef:', lr.coef_)\n",
    "print('score_train:',score_train)\n",
    "print('score_prediction:',score)\n",
    "print('e:',e)\n",
    "# list(lr.coef_) + [score, e, coeff_used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
